{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['no_kp', 'no_kp_lama', 'no_passport', 'no_sijil_kelahiran', 'nama',\n",
       "       'no_tel', 'tahun_lahir', 'id_jantina', 'id_agama', 'kump_etnik',\n",
       "       'id_etnik', 'id_warganegara', 'emel', 'id_status_kahwin', 'alamat_1',\n",
       "       'alamat_2', 'alamat_3', 'poskod', 'id_negeri', 'id_daerah', 'id_mukim',\n",
       "       'id_parlimen', 'id_dun', 'id_strata', 'id_taraf_pendidikan', 'id_sijil',\n",
       "       'id_jenis_pemilikan_kediaman', 'id_jenis_tempat_kediaman',\n",
       "       'id_jenis_pemilikan_kenderaan', 'id_jenis_kenderaan', 'no_plat',\n",
       "       'id_status_pekerjaan', 'id_jenis_pekerjaan', 'nama_majikan',\n",
       "       'no_daftar_majikan', 'id_jenis_kemahiran', 'id_penyakit',\n",
       "       'no_daftar_oku', 'id_jenis_oku', 'id_rawatan', 'no_akaun_bank',\n",
       "       'id_bank', 'id_jenis_akaun_bank', 'nilai_sumber_pendapatan',\n",
       "       'id_sumber_pendapatan', 'jumlah_pendapatan_bulanan',\n",
       "       'nilai_bantuan_diterima', 'kadar_bantuan_diterima', 'id_status_bantuan',\n",
       "       'tarikh_lulus', 'tarikh_terima_bantuan', 'tarikh_tamat_bantuan',\n",
       "       'id_kategori', 'id_bidang_fokus', 'id_kumpulan_fokus', 'id_teras',\n",
       "       'kaedah_pemberian', 'id_kekerapan', 'sektor', 'status_pelaksanaan',\n",
       "       'id_kumpulan_sasar', 'nama_program', 'id_agensi', 'id_kementerian',\n",
       "       'skop', 'papar_umum', 'sebab_tidak_aktif', 'syarat_program',\n",
       "       'id_status_pelaksanaan', 'tarikh_mula', 'tarikh_tamat',\n",
       "       'jumlah_peruntukan', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"E:\\BDA\\folder\\test_csv\\10) JKM_Bantuan Latihan Perantis.csv\", sep='|')   #check list of column names\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash==1.20.0\n",
      "  Downloading dash-1.20.0.tar.gz (77 kB)\n",
      "                                              0.0/77.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.6/77.6 kB 2.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting Flask>=1.0.4 (from dash==1.20.0)\n",
      "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "Collecting flask-compress (from dash==1.20.0)\n",
      "  Downloading Flask_Compress-1.13-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: plotly in e:\\bda\\vaex\\lib\\site-packages (from dash==1.20.0) (5.14.1)\n",
      "Collecting dash-renderer==1.9.1 (from dash==1.20.0)\n",
      "  Downloading dash_renderer-1.9.1.tar.gz (1.0 MB)\n",
      "                                              0.0/1.0 MB ? eta -:--:--\n",
      "     -------------                            0.3/1.0 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 12.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting dash-core-components==1.16.0 (from dash==1.20.0)\n",
      "  Downloading dash_core_components-1.16.0.tar.gz (3.5 MB)\n",
      "                                              0.0/3.5 MB ? eta -:--:--\n",
      "     --------------                           1.2/3.5 MB 25.9 MB/s eta 0:00:01\n",
      "     ------------------------------           2.7/3.5 MB 28.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.5/3.5 MB 31.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.5/3.5 MB 24.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting dash-html-components==1.1.3 (from dash==1.20.0)\n",
      "  Downloading dash_html_components-1.1.3.tar.gz (82 kB)\n",
      "                                              0.0/82.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 82.4/82.4 kB ? eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting dash-table==4.11.3 (from dash==1.20.0)\n",
      "  Downloading dash_table-4.11.3.tar.gz (1.8 MB)\n",
      "                                              0.0/1.8 MB ? eta -:--:--\n",
      "     -----------------                        0.8/1.8 MB 16.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.8/1.8 MB 23.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: future in e:\\bda\\vaex\\lib\\site-packages (from dash==1.20.0) (0.18.3)\n",
      "Requirement already satisfied: Werkzeug>=2.3.3 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash==1.20.0) (2.3.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash==1.20.0) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash==1.20.0) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash==1.20.0) (8.1.3)\n",
      "Requirement already satisfied: blinker>=1.6.2 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash==1.20.0) (1.6.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash==1.20.0) (6.6.0)\n",
      "Collecting brotli (from flask-compress->dash==1.20.0)\n",
      "  Using cached Brotli-1.0.9-cp38-cp38-win_amd64.whl (365 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in e:\\bda\\vaex\\lib\\site-packages (from plotly->dash==1.20.0) (8.2.2)\n",
      "Requirement already satisfied: packaging in e:\\bda\\vaex\\lib\\site-packages (from plotly->dash==1.20.0) (23.1)\n",
      "Requirement already satisfied: colorama in e:\\bda\\vaex\\lib\\site-packages (from click>=8.1.3->Flask>=1.0.4->dash==1.20.0) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\bda\\vaex\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash==1.20.0) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\bda\\vaex\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=1.0.4->dash==1.20.0) (2.1.2)\n",
      "Building wheels for collected packages: dash, dash-core-components, dash-html-components, dash-renderer, dash-table\n",
      "  Building wheel for dash (pyproject.toml): started\n",
      "  Building wheel for dash (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for dash: filename=dash-1.20.0-py3-none-any.whl size=85844 sha256=8e261cef397677fc7b22e9b0b2cfa92b92147978f00fe545a6a370c09857623d\n",
      "  Stored in directory: c:\\users\\najmi.ariffin\\appdata\\local\\pip\\cache\\wheels\\e3\\1e\\fa\\0c810b67f082a7b9f33a128f6374b03cf5245edc45e37adbf8\n",
      "  Building wheel for dash-core-components (pyproject.toml): started\n",
      "  Building wheel for dash-core-components (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for dash-core-components: filename=dash_core_components-1.16.0-py3-none-any.whl size=3540971 sha256=cb200fa395279000dd42e23b60a074fd2e5a339547fc7d9844dbc6f54129ac63\n",
      "  Stored in directory: c:\\users\\najmi.ariffin\\appdata\\local\\pip\\cache\\wheels\\68\\92\\0c\\4ac6d91639a754ebf3adfab7172c61fe408e7c71d00b8cbf66\n",
      "  Building wheel for dash-html-components (pyproject.toml): started\n",
      "  Building wheel for dash-html-components (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for dash-html-components: filename=dash_html_components-1.1.3-py3-none-any.whl size=319496 sha256=814307043754c387030b97512aa0fdff87a44e8b5e930f2482f20bc05344d94f\n",
      "  Stored in directory: c:\\users\\najmi.ariffin\\appdata\\local\\pip\\cache\\wheels\\2a\\a3\\33\\bf6842d5d279588f8989ee8c2f9d9d8feb7af82216493a1eea\n",
      "  Building wheel for dash-renderer (pyproject.toml): started\n",
      "  Building wheel for dash-renderer (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for dash-renderer: filename=dash_renderer-1.9.1-py3-none-any.whl size=1014857 sha256=11b21389bb39c96868a26e396c922d054416e333ef2e4746ee7c088c50e29868\n",
      "  Stored in directory: c:\\users\\najmi.ariffin\\appdata\\local\\pip\\cache\\wheels\\ac\\7e\\fd\\807844722d79d8babcd27b16e5f7ecc7b476c45ca607c11729\n",
      "  Building wheel for dash-table (pyproject.toml): started\n",
      "  Building wheel for dash-table (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for dash-table: filename=dash_table-4.11.3-py3-none-any.whl size=1827603 sha256=d32f4081afa5114402cf6c398547786956189aefef1a9e12a15980aeec75294f\n",
      "  Stored in directory: c:\\users\\najmi.ariffin\\appdata\\local\\pip\\cache\\wheels\\0c\\9c\\bd\\06904831bdaa998ad1f53584553c5e06324814328666699128\n",
      "Successfully built dash dash-core-components dash-html-components dash-renderer dash-table\n",
      "Installing collected packages: dash-table, dash-renderer, dash-html-components, dash-core-components, brotli, Flask, flask-compress, dash\n",
      "  Attempting uninstall: dash-table\n",
      "    Found existing installation: dash-table 5.0.0\n",
      "    Uninstalling dash-table-5.0.0:\n",
      "      Successfully uninstalled dash-table-5.0.0\n",
      "  Attempting uninstall: dash-html-components\n",
      "    Found existing installation: dash-html-components 2.0.0\n",
      "    Uninstalling dash-html-components-2.0.0:\n",
      "      Successfully uninstalled dash-html-components-2.0.0\n",
      "  Attempting uninstall: dash-core-components\n",
      "    Found existing installation: dash-core-components 2.0.0\n",
      "    Uninstalling dash-core-components-2.0.0:\n",
      "      Successfully uninstalled dash-core-components-2.0.0\n",
      "Successfully installed Flask-2.3.2 brotli-1.0.9 dash-1.20.0 dash-core-components-1.16.0 dash-html-components-1.1.3 dash-renderer-1.9.1 dash-table-4.11.3 flask-compress-1.13\n",
      "Collecting dash-table==4.12.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dash 1.20.0 requires dash-table==4.11.3, but you have dash-table 4.12.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading dash_table-4.12.0.tar.gz (1.8 MB)\n",
      "                                              0.0/1.8 MB ? eta -:--:--\n",
      "     ---------                                0.4/1.8 MB 9.2 MB/s eta 0:00:01\n",
      "     -----------------------------            1.4/1.8 MB 17.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.8/1.8 MB 14.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: dash-table\n",
      "  Building wheel for dash-table (pyproject.toml): started\n",
      "  Building wheel for dash-table (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for dash-table: filename=dash_table-4.12.0-py3-none-any.whl size=1837654 sha256=7f8dc56057bbf485f3cbb1a6a62c436e7db954814016f4e640a3ed524cdc29c0\n",
      "  Stored in directory: c:\\users\\najmi.ariffin\\appdata\\local\\pip\\cache\\wheels\\81\\20\\78\\23b49f61328cc14ddb5542b7a232a23c80891a9115fcd159d6\n",
      "Successfully built dash-table\n",
      "Installing collected packages: dash-table\n",
      "  Attempting uninstall: dash-table\n",
      "    Found existing installation: dash-table 4.11.3\n",
      "    Uninstalling dash-table-4.11.3:\n",
      "      Successfully uninstalled dash-table-4.11.3\n",
      "Successfully installed dash-table-4.12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash\n",
      "  Downloading dash-2.9.3-py3-none-any.whl (10.2 MB)\n",
      "                                              0.0/10.2 MB ? eta -:--:--\n",
      "                                              0.2/10.2 MB 4.6 MB/s eta 0:00:03\n",
      "     --                                       0.6/10.2 MB 6.9 MB/s eta 0:00:02\n",
      "     ---                                      0.9/10.2 MB 7.2 MB/s eta 0:00:02\n",
      "     ----                                     1.2/10.2 MB 6.3 MB/s eta 0:00:02\n",
      "     ------                                   1.6/10.2 MB 7.3 MB/s eta 0:00:02\n",
      "     --------                                 2.2/10.2 MB 7.7 MB/s eta 0:00:02\n",
      "     -----------                              2.9/10.2 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------                            3.5/10.2 MB 9.3 MB/s eta 0:00:01\n",
      "     ----------------                         4.3/10.2 MB 10.5 MB/s eta 0:00:01\n",
      "     --------------------                     5.3/10.2 MB 11.7 MB/s eta 0:00:01\n",
      "     -------------------------                6.4/10.2 MB 12.8 MB/s eta 0:00:01\n",
      "     -----------------------------            7.6/10.2 MB 13.8 MB/s eta 0:00:01\n",
      "     -----------------------------------      9.0/10.2 MB 14.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.2/10.2 MB 16.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.2/10.2 MB 16.0 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.2/10.2 MB 14.2 MB/s eta 0:00:00\n",
      "Collecting Flask>=1.0.4 (from dash)\n",
      "  Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "                                              0.0/96.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 96.9/96.9 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting plotly>=5.0.0 (from dash)\n",
      "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
      "                                              0.0/15.3 MB ? eta -:--:--\n",
      "     ---                                      1.2/15.3 MB 25.1 MB/s eta 0:00:01\n",
      "     ------                                   2.6/15.3 MB 27.3 MB/s eta 0:00:01\n",
      "     ----------                               4.1/15.3 MB 29.2 MB/s eta 0:00:01\n",
      "     --------------                           5.6/15.3 MB 32.4 MB/s eta 0:00:01\n",
      "     ------------------                       7.0/15.3 MB 32.0 MB/s eta 0:00:01\n",
      "     ----------------------                   8.6/15.3 MB 30.7 MB/s eta 0:00:01\n",
      "     -------------------------               10.2/15.3 MB 30.9 MB/s eta 0:00:01\n",
      "     -----------------------------           11.8/15.3 MB 32.8 MB/s eta 0:00:01\n",
      "     ---------------------------------       13.2/15.3 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------    14.5/15.3 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  15.3/15.3 MB 32.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  15.3/15.3 MB 32.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 15.3/15.3 MB 24.2 MB/s eta 0:00:00\n",
      "Collecting dash-html-components==2.0.0 (from dash)\n",
      "  Using cached dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash)\n",
      "  Using cached dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: dash-table==5.0.0 in e:\\bda\\vaex\\lib\\site-packages (from dash) (5.0.0)\n",
      "Collecting Werkzeug>=2.3.3 (from Flask>=1.0.4->dash)\n",
      "  Downloading Werkzeug-2.3.3-py3-none-any.whl (242 kB)\n",
      "                                              0.0/242.3 kB ? eta -:--:--\n",
      "     ------------------------------------- 242.3/242.3 kB 15.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash) (3.1.2)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask>=1.0.4->dash)\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash) (8.1.3)\n",
      "Collecting blinker>=1.6.2 (from Flask>=1.0.4->dash)\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in e:\\bda\\vaex\\lib\\site-packages (from Flask>=1.0.4->dash) (6.6.0)\n",
      "Collecting tenacity>=6.2.0 (from plotly>=5.0.0->dash)\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: packaging in e:\\bda\\vaex\\lib\\site-packages (from plotly>=5.0.0->dash) (23.1)\n",
      "Requirement already satisfied: colorama in e:\\bda\\vaex\\lib\\site-packages (from click>=8.1.3->Flask>=1.0.4->dash) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\bda\\vaex\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\bda\\vaex\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=1.0.4->dash) (2.1.2)\n",
      "Installing collected packages: dash-html-components, dash-core-components, Werkzeug, tenacity, itsdangerous, blinker, plotly, Flask, dash\n",
      "Successfully installed Flask-2.3.2 Werkzeug-2.3.3 blinker-1.6.2 dash-1.20.0 dash-core-components-1.16.0 dash-html-components-1.1.3 itsdangerous-2.1.2 plotly-5.14.1 tenacity-8.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install dash==1.20.0\n",
    "!pip install dash-table==4.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import dash_table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set reference column names\n",
    "ref_cols = ['no_kp', 'no_kp_lama', 'no_passport', 'no_sijil_kelahiran', 'nama',\n",
    "       'no_tel', 'tahun_lahir', 'id_jantina', 'id_agama', 'kump_etnik',\n",
    "       'id_etnik', 'id_warganegara', 'emel', 'id_status_kahwin', 'alamat_1',\n",
    "       'alamat_2', 'alamat_3', 'poskod', 'id_negeri', 'id_daerah', 'id_mukim',\n",
    "       'id_parlimen', 'id_dun', 'id_strata', 'id_taraf_pendidikan', 'id_sijil',\n",
    "       'id_jenis_pemilikan_kediaman', 'id_jenis_tempat_kediaman',\n",
    "       'id_jenis_pemilikan_kenderaan', 'id_jenis_kenderaan', 'no_plat',\n",
    "       'id_status_pekerjaan', 'id_jenis_pekerjaan', 'nama_majikan',\n",
    "       'no_daftar_majikan', 'id_jenis_kemahiran', 'id_penyakit',\n",
    "       'no_daftar_oku', 'id_jenis_oku', 'id_rawatan', 'no_akaun_bank',\n",
    "       'id_bank', 'id_jenis_akaun_bank', 'nilai_sumber_pendapatan',\n",
    "       'id_sumber_pendapatan', 'jumlah_pendapatan_bulanan',\n",
    "       'nilai_bantuan_diterima', 'kadar_bantuan_diterima', 'id_status_bantuan',\n",
    "       'tarikh_lulus', 'tarikh_terima_bantuan', 'tarikh_tamat_bantuan',\n",
    "       'id_kategori', 'id_bidang_fokus', 'id_kumpulan_fokus', 'id_teras',\n",
    "       'kaedah_pemberian', 'id_kekerapan', 'sektor', 'status_pelaksanaan',\n",
    "       'id_kumpulan_sasar', 'nama_program', 'id_agensi', 'id_kementerian',\n",
    "       'skop', 'papar_umum', 'sebab_tidak_aktif', 'syarat_program',\n",
    "       'id_status_pelaksanaan', 'tarikh_mula', 'tarikh_tamat',\n",
    "       'jumlah_peruntukan', 'url']\n",
    "\n",
    "# set folder path for CSV files\n",
    "# folder_path = r\"E:\\BDA\\folder\\test_csv\" #set folder directory\n",
    "folder_path = r\"C:\\Users\\najmi.ariffin\\git-najmi\\batch1_csv\" #set folder directory\n",
    "\n",
    "# get all CSV files in folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# create a dictionary to hold the dataframes for each CSV file\n",
    "dfs = {}\n",
    "for file in csv_files:\n",
    "    dfs[file] = pd.read_csv(os.path.join(folder_path, file), sep='|', low_memory=False)\n",
    "\n",
    "# create a function to generate the dash-table for a given dataframe\n",
    "def generate_table(df):\n",
    "    return dash_table.DataTable(\n",
    "        id='table',\n",
    "        columns=[{'name': i, 'id': i} for i in df.columns],\n",
    "        data=df.to_dict('records'),\n",
    "        filter_action='native',\n",
    "        sort_action='native',\n",
    "        sort_mode='multi',\n",
    "        page_size=10\n",
    "    )\n",
    "\n",
    "# create the app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# define the layout\n",
    "app.layout = dash.html.Div(children=[\n",
    "    dash.html.H1(children='Data Quality Management'),\n",
    "\n",
    "    dash.html.Div(children='''\n",
    "        DQM report for CSV files in a directory.\n",
    "    '''),\n",
    "\n",
    "    # create a dropdown to select the CSV file\n",
    "    dash.dcc.Dropdown(\n",
    "        id='file-dropdown',\n",
    "        options=[{'label': f, 'value': f} for f in csv_files],\n",
    "        value=csv_files[0]\n",
    "    ),\n",
    "\n",
    "    # create a div to display the table\n",
    "    dash.html.Div(id='table-container')\n",
    "])\n",
    "\n",
    "# create a callback to update the table when a new CSV file is selected\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('table-container', 'children'),\n",
    "    [dash.dependencies.Input('file-dropdown', 'value')])\n",
    "def update_table(value):\n",
    "    return generate_table(dfs[value])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQM Code Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to dqm_spc.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import markdown2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set reference column names #set column names\n",
    "ref_cols = ['no_kp', 'no_kp_lama', 'no_passport', 'no_sijil_kelahiran', 'nama',\n",
    "       'no_tel', 'tahun_lahir', 'id_jantina', 'id_agama', 'kump_etnik',\n",
    "       'id_etnik', 'id_warganegara', 'emel', 'id_status_kahwin', 'alamat_1',\n",
    "       'alamat_2', 'alamat_3', 'poskod', 'id_negeri', 'id_daerah', 'id_mukim',\n",
    "       'id_parlimen', 'id_dun', 'id_strata', 'id_taraf_pendidikan', 'id_sijil',\n",
    "       'id_jenis_pemilikan_kediaman', 'id_jenis_tempat_kediaman',\n",
    "       'id_jenis_pemilikan_kenderaan', 'id_jenis_kenderaan', 'no_plat',\n",
    "       'id_status_pekerjaan', 'id_jenis_pekerjaan', 'nama_majikan',\n",
    "       'no_daftar_majikan', 'id_jenis_kemahiran', 'id_penyakit',\n",
    "       'no_daftar_oku', 'id_jenis_oku', 'id_rawatan', 'no_akaun_bank',\n",
    "       'id_bank', 'id_jenis_akaun_bank', 'nilai_sumber_pendapatan',\n",
    "       'id_sumber_pendapatan', 'jumlah_pendapatan_bulanan',\n",
    "       'nilai_bantuan_diterima', 'kadar_bantuan_diterima', 'id_status_bantuan',\n",
    "       'tarikh_lulus', 'tarikh_terima_bantuan', 'tarikh_tamat_bantuan',\n",
    "       'id_kategori', 'id_bidang_fokus', 'id_kumpulan_fokus', 'id_teras',\n",
    "       'kaedah_pemberian', 'id_kekerapan', 'sektor', 'status_pelaksanaan',\n",
    "       'id_kumpulan_sasar', 'nama_program', 'id_agensi', 'id_kementerian',\n",
    "       'skop', 'papar_umum', 'sebab_tidak_aktif', 'syarat_program',\n",
    "       'id_status_pelaksanaan', 'tarikh_mula', 'tarikh_tamat',\n",
    "       'jumlah_peruntukan', 'url']\n",
    "\n",
    "# set folder path for CSV files\n",
    "folder_path = r\"C:\\Users\\najmi.ariffin\\git-najmi\\batch1_csv\" #set folder directory\n",
    "# folder_path = r\"E:\\BDA\\folder\\test_csv\" #set folder directory\n",
    "\n",
    "# get all CSV files in folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# initialize Markdown table\n",
    "md_table = '| Filename | No. of Columns | No. of Records | % of Missing Data | No. of Categorical Columns | No. of Numeric Columns | Same Column Names | Valid no_kp | Invalid no_kp |\\n'\n",
    "md_table += '| --- | --- | --- | --- | --- | --- | --- |\\n'\n",
    "\n",
    "# loop over CSV files\n",
    "for file in csv_files:\n",
    "    # read CSV file into a dataframe\n",
    "    df = pd.read_csv(os.path.join(folder_path, file), sep='|', low_memory=False)\n",
    "\n",
    "    # check number of columns\n",
    "    cols_val = str(len(df.columns))\n",
    "\n",
    "    # check number of records\n",
    "    rec_val = str(len(df))\n",
    "\n",
    "    # check number of missing data\n",
    "    miss_val = str(df.isnull().sum().sum())\n",
    "    miss_pct = f'{(df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100:.2f}%'\n",
    "\n",
    "    # check number of columns with categorical attribute\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    cat_val = str(len(cat_cols))\n",
    "\n",
    "    # check number of columns with numeric attribute\n",
    "    num_cols = [col for col in df.columns if np.issubdtype(df[col].dtype, np.number)]\n",
    "    num_val = str(len(num_cols))\n",
    "\n",
    "    # check if column names are the same or different\n",
    "    cols_names_val = '✔️' if list(df.columns) == ref_cols else '❌'\n",
    "    \n",
    "    # count number of valid and invalid values in column 'no_kp'\n",
    "    valid_no_kp = str(len(df[df['no_kp'].astype(str).str.len() == 12]))\n",
    "    invalid_no_kp = str(len(df[df['no_kp'].astype(str).str.len() != 12]))\n",
    "\n",
    "    # add row to Markdown table\n",
    "    md_table += f'| {file} | {cols_val} | {rec_val} | {miss_pct} | {cat_val} | {num_val} | {cols_names_val} | {valid_no_kp} | {invalid_no_kp} |\\n'\n",
    "\n",
    "# convert Markdown to HTML\n",
    "html_table = markdown2.markdown(md_table, extras=[\"tables\"])\n",
    "\n",
    "# write HTML to file\n",
    "filename = 'dqm_spc'\n",
    "with open(filename +\".html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_table.replace('<table>', '<table border=\"1\">'))\n",
    "    \n",
    "print('Output saved to ' + filename + '.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Monitoring (DQM)\n",
    "\n",
    "This Python code performs an analysis of CSV files located in a specified folder. The code imports several Python libraries, including Pandas for data manipulation, Numpy for numerical calculations, OS for directory and file handling, Markdown2 for formatting text, and Matplotlib for data visualization.\n",
    "\n",
    "## Initialize Installation\n",
    "\n",
    "First, the code sets a list of column names that will serve as a reference for all CSV files. The code also sets the directory path to the folder containing the CSV files.\n",
    "\n",
    "    - The code reads multiple CSV files in a specified directory, performs various data checks on each file, and generates an HTML table summarizing the results. \n",
    "    - The required libraries are imported - Pandas, NumPy, os, markdown2, and matplotlib.pyplot.\n",
    "    - A list of reference column names is set.\n",
    "\n",
    "The code then uses the OS library to get a list of all CSV files in the specified folder. For each CSV file in the list, the code reads it into a Pandas DataFrame and performs several checks to determine various characteristics of the data. These characteristics include the number of columns, number of records, percentage of missing data, number of columns with categorical data, and number of columns with numerical data.\n",
    "\n",
    "    - The folder path where the CSV files are located is set.\n",
    "    - A list of CSV files in the specified folder is obtained using the os.listdir() function.\n",
    "    - An empty Markdown table is initialized with column headers.\n",
    "\n",
    "## Loop over CSV files\n",
    "\n",
    "    - The code loops over each CSV file in the list of CSV files obtained in step 4.\n",
    "    - For each CSV file, the file is read into a Pandas DataFrame using the pd.read_csv() function. The sep argument is set to '|' to handle the delimiter used in the CSV file.\n",
    "\n",
    "The following data checks are performed on each DataFrame:\n",
    "\n",
    "    - The number of columns is calculated.\n",
    "    - The number of records is calculated.\n",
    "    - The number of missing values is calculated and expressed as a percentage of the total number of cells.\n",
    "    - The number of columns with categorical attributes is calculated.\n",
    "    - The number of columns with numeric attributes is calculated.\n",
    "    - A check is performed to see if the column names are the same as the reference column names.\n",
    "    - The number of valid and invalid values in the 'no_kp' column is calculated. 'no_kp' is a Malaysian identification number, which should have 12 digits.\n",
    "    - A row is added to the Markdown table with the results obtained in step 8.\n",
    "\n",
    "The code also checks if the column names in each CSV file match the reference column names specified earlier. If they do match, the code adds a checkmark to the output table, and if they do not match, it adds an \"X\" mark.\n",
    "\n",
    "## Convert Markdown to HTML\n",
    "Finally, the code counts the number of valid and invalid values in the \"no_kp\" column, which is a unique identifier in the dataset. The code then generates an output table in Markdown format, which is converted to HTML format using the Markdown2 library. The resulting HTML file is saved to the specified location, and the code prints a message confirming that the output was saved.\n",
    "\n",
    "    -Once all CSV files have been processed, the Markdown table is converted to an HTML table using the markdown2.markdown() function.\n",
    "    -The HTML table is written to a file called \"table2.html\".\n",
    "    -The output message \"Output saved to table2.html\" is printed.\n",
    "    -To generate the Markdown table with code, one would need to modify the code to add a Markdown cell to a Jupyter Notebook or use an online Markdown editor. The code can then be pasted into the Markdown cell and executed.\n",
    "\n",
    "Overall, this code provides a quick and automated way to assess the quality of data in a set of CSV files, which could be useful for data analysts and data scientists.\n",
    "\n",
    "\n",
    "### Code breakdown\n",
    "1. The script imports necessary libraries, such as pandas, numpy, os, and markdown2.\n",
    "2. The script defines a list of column names (ref_cols) that will be used as a reference to check if the column names in each CSV file are the same.\n",
    "3. The script defines a folder path for the CSV files to be analyzed (folder_path).\n",
    "4. The script uses the os library to get a list of all CSV files in the specified folder.\n",
    "5. The script initializes an empty Markdown table (md_table) with headers for the columns that will be filled in later.\n",
    "6. The script loops over each CSV file in the list of CSV files.\n",
    "7. For each CSV file, the script uses pandas to read the file into a dataframe (df).\n",
    "8. The script then performs several analyses on the dataframe and retrieves information about the number of columns, number of records, number of missing data, number of categorical and numeric columns, and validity of the column names.\n",
    "9. The script also counts the number of valid and invalid values in the 'no_kp' column.\n",
    "10. The script adds a row to the Markdown table for each CSV file, filling in the information obtained from the dataframe analyses.\n",
    "11. Once all CSV files have been analyzed and the Markdown table is complete, the script uses the markdown2 library to convert the Markdown table to HTML (html_table).\n",
    "12. The script then writes the HTML table to a file named \"table2.html\" and includes a border for each cell.\n",
    "13. Finally, the script prints a message confirming that the output has been saved to \"table2.html\".\n",
    "\n",
    "Overall, this script provides a convenient way to analyze multiple CSV files and summarize important information about each file in a clear and concise HTML table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
